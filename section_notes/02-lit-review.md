

# Literature Review

## Research Focus & Methodology

This literature review examines AI-assisted research platforms and tools, following the Computer Science-inspired research methodology. We focus on identifying **fundamental assumptions** across the literature that can be challenged to unlock new research directions for platforms like Oslo.

### Core Research Question
**What assumptions underlie current AI research assistance tools, and how can we flip these assumptions to create more effective research collaboration platforms?**

## Literature Analysis Framework

Following our research methodology, each paper is analyzed using this structure:
1. **Problem** - What core problem is being solved?
2. **Prior Assumptions** - What assumptions did earlier work make?
3. **Insight** - What novel idea breaks from those assumptions?
4. **Technical Approach** - How was the insight implemented?
5. **Evaluation** - How was it validated?
6. **Impact** - What are the field-wide implications?

## Key Research Areas

### 1. Literature Review Automation & Research Discovery

#### Fundamental Assumptions in Current Literature:
- **Assumption A1**: Researchers need better search algorithms to find relevant papers
- **Assumption A2**: Literature review is primarily an individual, sequential process
- **Assumption A3**: Quality literature review requires manual human synthesis

#### Research Gap Identified:
Most current tools focus on **finding** papers rather than **synthesizing insights** across papers to identify literature-level assumptions that can be flipped.

### 2. AI Research Collaboration & Peer Review

#### Fundamental Assumptions in Current Literature:
- **Assumption B1**: Peer review quality correlates with reviewer expertise matching
- **Assumption B2**: Research collaboration requires synchronous human coordination
- **Assumption B3**: AI can only assist with mechanical tasks, not conceptual reasoning

#### Research Gap Identified:
Limited exploration of AI systems that can identify **conflicting assumptions** across papers and suggest novel research directions through assumption inversion.

### 3. Research Workflow & Reproducibility

#### Fundamental Assumptions in Current Literature:
- **Assumption C1**: Reproducibility requires detailed manual documentation
- **Assumption C2**: Research workflows are linear and predictable
- **Assumption C3**: Experiment tracking is separate from hypothesis generation

#### Research Gap Identified:
Missing integration between **assumption tracking** and **experiment design** - most tools track what was done, not what assumptions were tested.

## Literature-Level Hypothesis

### Core Assumption to Flip:
**Current Assumption**: AI research tools should optimize individual researcher productivity

### Our Hypothesis**: AI research tools should optimize **collective knowledge synthesis** by identifying and testing literature-level assumptions

### Impact Validation:
This flip affects multiple research areas:
- Literature review becomes assumption discovery rather than paper summarization
- Collaboration becomes assumption-testing rather than task-sharing
- Reproducibility becomes assumption-validation rather than method-documentation

## Structured Paper Analysis

### Template for Additional Papers

For each paper added to this review, use this structure:

#### Paper Template
- **Citation**: [Full citation]
- **Problem**: What core problem is being solved? Why does it matter?
- **Prior Assumptions**: What assumption did prior research make? Why was it inadequate?
- **Insight**: What novel idea breaks from that assumption?
- **Technical Approach**: How was the insight implemented?
- **Evaluation**: How was the insight validated? What evidence was provided?
- **Impact**: What are the implications? How will it change the field?
- **Assumption Categories**: Which of our identified assumptions (A1-C3) does this relate to?
- **Relevance to Oslo**: How does this inform our AI co-scientist platform?

## Research Synthesis

### Cross-Paper Themes

1. **Assumption Pattern**: Most tools optimize for efficiency rather than insight generation
2. **Technical Pattern**: Focus on information retrieval rather than knowledge synthesis
3. **Evaluation Pattern**: Measured by speed/accuracy rather than research impact

### Implications for Oslo Platform

Based on this literature analysis, Oslo should focus on:
1. **Assumption Discovery**: Help researchers identify implicit assumptions in literature
2. **Hypothesis Generation**: Suggest novel research directions through assumption inversion
3. **Collective Intelligence**: Enable collaborative assumption testing across research teams

## Next Steps for Literature Enhancement

1. **Paper Collection**: Use ArXiv, Google Scholar, and Semantic Scholar to find papers in identified areas
2. **Systematic Analysis**: Apply the 6-point framework to each paper
3. **Assumption Mapping**: Identify patterns in assumptions across papers
4. **Gap Validation**: Confirm that assumption-flipping represents genuine research opportunities

## Research Methodology Notes

*Following CLAUDE.md guidance: "After ~5 papers, you'll see diminishing returns. PhD-level research typically reviews 25-35 papers."*

**Target**: 25-30 high-quality papers from 2020-2024
**Focus**: Papers from top venues (NeurIPS, ICML, CHI, CSCW, AAAI) that demonstrate clear assumption-challenging insights
**Priority**: Papers that span multiple assumption categories (A1-C3) for maximum synthesis potential

